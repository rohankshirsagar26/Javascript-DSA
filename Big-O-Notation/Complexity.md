Complexity

    In the world of computer science, to perform better, you need to write algorithms that are time efficient and use less memory.
    An algorithm's complexity is a measure of the amount of data that it must process in order to be efficient.

    A good algorithm executes quickly and saves space in the process.

Time Complexity

    Time complexity is a type of computational complexity that describes the time required to execute an algorithm based on the length of the given input.

Space Complexity

    Space complexity is a type of computational complexity that describes the amount of memory used by a program to execute.

Asymptotic Notations

    Asymptotic Notations are programming languages that allow you to analyze an algorithm's running time by identifying its behavior as its input size grows.
    Asymptotic Notation is also referred to as an algorithm's growth rate.

    You can't compare two algorithms head to head. It is heavily influenced by the tools and hardware you use for comparisons, such as the operating system, CPU model, processor generation, and so on.

    Even if you calculate time and space complexity for two algorithms running on the same system, the subtle changes in the system environment may affect their time and space complexity.
    As a result, you compare space and time complexity using asymptotic analysis. It compares two algorithms based on changes in their performance as the input size is increased or decreased.

    Asymptotic notations are classified into three types:

        1. Big-Oh (O) notation
        2. Big Omega ( Ω ) notation
        3. Big Theta ( Θ ) notation
